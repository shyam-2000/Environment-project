{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Semantic segmentation**"
      ],
      "metadata": {
        "id": "Tuq4WtccL6BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:1\n",
        "Importing all the necessary libraries to visualize the map and for model building."
      ],
      "metadata": {
        "id": "q_hU3cfq2xof"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zKlLBIzs-RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6345b82-8230-4ae5-a1a4-8414c82685fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting geemap\n",
            "  Downloading geemap-0.22.1-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bqplot (from geemap)\n",
            "  Downloading bqplot-0.12.39-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colour (from geemap)\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: earthengine-api>=0.1.347 in /usr/local/lib/python3.10/dist-packages (from geemap) (0.1.350)\n",
            "Collecting eerepr>=0.0.4 (from geemap)\n",
            "  Downloading eerepr-0.0.4-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: folium>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from geemap) (0.14.0)\n",
            "Collecting geocoder (from geemap)\n",
            "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipyevents (from geemap)\n",
            "  Downloading ipyevents-2.0.1-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipyfilechooser>=0.6.0 (from geemap)\n",
            "  Downloading ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting ipyleaflet>=0.17.0 (from geemap)\n",
            "  Downloading ipyleaflet-0.17.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipytree (from geemap)\n",
            "  Downloading ipytree-0.2.2-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from geemap) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geemap) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from geemap) (1.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from geemap) (5.13.1)\n",
            "Collecting pyperclip (from geemap)\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyshp>=2.1.3 (from geemap)\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-box (from geemap)\n",
            "  Downloading python_box-7.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scooby (from geemap)\n",
            "  Downloading scooby-0.7.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (0.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (0.21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from earthengine-api>=0.1.347->geemap) (2.27.1)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium>=0.13.0->geemap) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium>=0.13.0->geemap) (3.1.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from ipyfilechooser>=0.6.0->geemap) (7.7.1)\n",
            "Collecting traittypes<3,>=0.2.1 (from ipyleaflet>=0.17.0->geemap)\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting xyzservices>=2021.8.1 (from ipyleaflet>=0.17.0->geemap)\n",
            "  Downloading xyzservices-2023.5.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from bqplot->geemap) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->geemap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->geemap) (2022.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geocoder->geemap) (8.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from geocoder->geemap) (0.18.3)\n",
            "Collecting ratelim (from geocoder->geemap)\n",
            "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geocoder->geemap) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->geemap) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->geemap) (8.2.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=0.1.347->geemap) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api>=0.1.347->geemap) (4.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.347->geemap) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.347->geemap) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api>=0.1.347->geemap) (4.9)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium>=0.13.0->geemap) (2.1.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api>=0.1.347->geemap) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api>=0.1.347->geemap) (2.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api>=0.1.347->geemap) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api>=0.1.347->geemap) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api>=0.1.347->geemap) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api>=0.1.347->geemap) (3.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ratelim->geocoder->geemap) (4.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=0.1.347->geemap) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api>=0.1.347->geemap) (3.20.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->earthengine-api>=0.1.347->geemap) (1.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.8.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api>=0.1.347->geemap) (0.5.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.4.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.8.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (5.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (3.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (21.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser>=0.6.0->geemap) (2.21)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=5aea0e14448040610d9b3e3ccbfaae4b7f2126a4d5c231da33f6df75fa82afcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/24/fe/140a94a7f1036003ede94579e6b4227fe96c840c6f4dcbe307\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, colour, xyzservices, traittypes, scooby, ratelim, python-box, pyshp, jedi, geocoder, eerepr, ipytree, ipyleaflet, ipyfilechooser, ipyevents, bqplot, geemap\n",
            "Successfully installed bqplot-0.12.39 colour-0.1.5 eerepr-0.0.4 geemap-0.22.1 geocoder-1.38.1 ipyevents-2.0.1 ipyfilechooser-0.6.0 ipyleaflet-0.17.3 ipytree-0.2.2 jedi-0.18.2 pyperclip-1.8.2 pyshp-2.3.1 python-box-7.0.1 ratelim-0.1.6 scooby-0.7.2 traittypes-0.2.1 xyzservices-2023.5.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "import IPython.display as disp\n",
        "\n",
        "!pip install geemap\n",
        "import geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:2\n",
        "Authenticating the earth engine."
      ],
      "metadata": {
        "id": "j35-8PhJ3-S2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on9wMaIEtRbS",
        "outputId": "7a12780e-61ff-4c7d-dd19-dac960d4f0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=m_BT5-nBSIElHLAfeAiidnGF52N8z5lDfd6hLqNzAHA&tc=aBrScdR-BW4oEnvo-QJi7qP06gmTfqlFstZhQ5ejGp0&cc=OmOQYvCtOXXsWRgYitkk9-r9GHg4K9NPXyJMBgUnjX8\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AbUR2VPY5xxJkFipk0d0Rf3S_72wiRh7r3WOThlRTwNUcSLWF2qGvl_HcX4\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "LzrBa3C1hGTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1FZF_0XaNh3",
        "outputId": "f13e1d0a-66df-408d-cedf-1b461866d544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:3\n",
        "Initialize the earth engine and import the folium package for visualization."
      ],
      "metadata": {
        "id": "7SyFL7GJnH7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du2zCApMtbR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e341086f-4812-4367-decc-1cc53809f0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: earthengine upload image\n",
            "       [-h]\n",
            "       [--wait [WAIT]]\n",
            "       [--force]\n",
            "       [--asset_id ASSET_ID]\n",
            "       [--last_band_alpha]\n",
            "       [--nodata_value NODATA_VALUE]\n",
            "       [--pyramiding_policy PYRAMIDING_POLICY]\n",
            "       [--bands BANDS]\n",
            "       [--crs CRS]\n",
            "       [--manifest MANIFEST]\n",
            "       [--property PROPERTY]\n",
            "       [--time_start TIME_START]\n",
            "       [--time_end TIME_END]\n",
            "       [src_files ...]\n",
            "\n",
            "Uploads an\n",
            "image from\n",
            "Cloud\n",
            "Storage to\n",
            "Earth\n",
            "Engine. See\n",
            "docs for\n",
            "\"asset set\"\n",
            "for\n",
            "additional\n",
            "details on\n",
            "how to\n",
            "specify\n",
            "asset\n",
            "metadata\n",
            "properties.\n",
            "\n",
            "positional arguments:\n",
            "  src_files\n",
            "    Cloud\n",
            "    Storage\n",
            "    URL(s) of\n",
            "    the file(s)\n",
            "    to upload.\n",
            "    Must have\n",
            "    the prefix\n",
            "    'gs://'.\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --wait [WAIT], -w [WAIT]\n",
            "    Wait for\n",
            "    the task to\n",
            "    finish, or\n",
            "    timeout\n",
            "    after the\n",
            "    specified\n",
            "    number of\n",
            "    seconds.\n",
            "    Without\n",
            "    this flag,\n",
            "    the command\n",
            "    just starts\n",
            "    an export\n",
            "    task in the\n",
            "    background,\n",
            "    and returns\n",
            "    immediately\n",
            "    .\n",
            "  --force, -f\n",
            "    Overwrite\n",
            "    any\n",
            "    existing\n",
            "    version of\n",
            "    the asset.\n",
            "  --asset_id ASSET_ID\n",
            "    Destination\n",
            "    asset ID\n",
            "    for the\n",
            "    uploaded\n",
            "    file.\n",
            "  --last_band_alpha\n",
            "    Use the\n",
            "    last band\n",
            "    as a\n",
            "    masking\n",
            "    channel for\n",
            "    all bands.\n",
            "    Mutually\n",
            "    exclusive\n",
            "    with nodata\n",
            "    _value.\n",
            "  --nodata_value NODATA_VALUE\n",
            "    Value for\n",
            "    missing\n",
            "    data.\n",
            "    Mutually\n",
            "    exclusive\n",
            "    with last_b\n",
            "    and_alpha.\n",
            "  --pyramiding_policy PYRAMIDING_POLICY\n",
            "    The pyramid\n",
            "    reduction\n",
            "    policy to\n",
            "    use\n",
            "  --bands BANDS\n",
            "    Comma-\n",
            "    separated\n",
            "    list of\n",
            "    names to\n",
            "    use for the\n",
            "    image\n",
            "    bands.\n",
            "  --crs CRS\n",
            "    The\n",
            "    coordinate\n",
            "    reference\n",
            "    system, to\n",
            "    override\n",
            "    the map\n",
            "    projection\n",
            "    of the\n",
            "    image. May\n",
            "    be either a\n",
            "    well-known\n",
            "    authority\n",
            "    code (e.g.\n",
            "    EPSG:4326)\n",
            "    or a WKT\n",
            "    string.\n",
            "  --manifest MANIFEST\n",
            "    Local path\n",
            "    to a JSON\n",
            "    asset\n",
            "    manifest\n",
            "    file. No\n",
            "    other flags\n",
            "    are used if\n",
            "    this flag\n",
            "    is set.\n",
            "  --property PROPERTY, -p PROPERTY\n",
            "    A property\n",
            "    to set, in\n",
            "    the form [(\n",
            "    type)]name=\n",
            "    value. If\n",
            "    no type is\n",
            "    specified\n",
            "    the type\n",
            "    will be\n",
            "    \"number\" if\n",
            "    the value\n",
            "    is numeric\n",
            "    and\n",
            "    \"string\"\n",
            "    otherwise.\n",
            "    May be\n",
            "    provided\n",
            "    multiple\n",
            "    times.\n",
            "  --time_start TIME_START, -ts TIME_START\n",
            "    Sets the\n",
            "    start time\n",
            "    property to\n",
            "    a number or\n",
            "    date.\n",
            "  --time_end TIME_END, -te TIME_END\n",
            "    Sets the\n",
            "    end time\n",
            "    property to\n",
            "    a number or\n",
            "    date.\n"
          ]
        }
      ],
      "source": [
        "import ee\n",
        "ee.Initialize()\n",
        "\n",
        "# Test the earthengine command by getting help on upload.\n",
        "!earthengine upload image -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkPDrdn8kIml",
        "outputId": "a5e6e61c-afc3-4dad-dd2b-606baf3993dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14.0\n"
          ]
        }
      ],
      "source": [
        "import folium\n",
        "print(folium.__version__)\n",
        "\n",
        "# Define the URL format used for Earth Engine generated map tiles.\n",
        "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:4\n",
        "Collecting images from landsat 8 with corresponding bands and labels, appending them together."
      ],
      "metadata": {
        "id": "1RB-RaXHv1W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Earth Engine username is used to import a classified image\n",
        "# into the Earth Engine assets folder.\n",
        "USER_NAME = 'ee-ssasikumar'\n",
        "\n",
        "# I made a Cloud Storage bucket in google cloud into which training, testing and prediction datasets will be written.\n",
        "OUTPUT_BUCKET = 'environment_project'\n",
        "\n",
        "# Use Landsat 8 surface reflectance data for predictors.\n",
        "L8SR = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
        "# Use these bands for prediction.\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "# This is a training/testing dataset of points with known land cover labels.\n",
        "LABEL_DATA = ee.FeatureCollection('projects/google/demo_landcover_labels')\n",
        "\n",
        "# The labels, consecutive integer indices starting from zero, are stored in\n",
        "# this property, set on each point.\n",
        "LABEL = 'landcover'\n",
        "\n",
        "# Number of label values, i.e. number of classes in the classification.\n",
        "N_CLASSES = 3\n",
        "\n",
        "# These names are used to specify properties in the export of training/testing data and to define the mapping between names and data\n",
        "# when reading into TensorFlow datasets.\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "# File names for the training and testing datasets.  These TFRecord files\n",
        "# will be exported from Earth Engine into the Cloud Storage bucket.\n",
        "TRAIN_FILE_PREFIX = 'Training_demo'\n",
        "TEST_FILE_PREFIX = 'Testing_demo'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n",
        "\n",
        "# File name for the prediction (image) dataset.  The trained model will read\n",
        "# this dataset and make predictions in each pixel.\n",
        "IMAGE_FILE_PREFIX = 'Image_pixel_demo_'\n",
        "\n",
        "# The output path for the classified image (i.e. predictions) TFRecord file.\n",
        "OUTPUT_IMAGE_FILE = 'gs://' + OUTPUT_BUCKET + '/Classified_pixel_demo.TFRecord'\n",
        "\n",
        "# Export imagery in this region.\n",
        "EXPORT_REGION = ee.Geometry.Rectangle([-122.7, 37.3, -121.8, 38.00])#roi\n",
        "\n",
        "# Path to the Earth Engine asset for importing  the classified image from the TFRecord file in Cloud Storage.\n",
        "OUTPUT_ASSET_ID = 'projects/ee-ssasikumar/assets/Classified_pixel_demo'"
      ],
      "metadata": {
        "id": "KN8Xq9qL5R2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:5\n",
        "Create the mask function to remove the cloud and visualize it using folium on the map."
      ],
      "metadata": {
        "id": "8AQxqFP2wJe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "id": "aJEQ9EHTkMEa",
        "outputId": "0b27cccb-a3b1-4898-fe82-1fab8c27114a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7f19e319f5e0>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_e6b6e244eac68c2abfcda706ac50be90 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_e6b6e244eac68c2abfcda706ac50be90&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_e6b6e244eac68c2abfcda706ac50be90 = L.map(\n",
              "                &quot;map_e6b6e244eac68c2abfcda706ac50be90&quot;,\n",
              "                {\n",
              "                    center: [9.714855444616322, 76.32380968048625],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_6ec574f59d2a07f0e6698c674f839ddf = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_e6b6e244eac68c2abfcda706ac50be90);\n",
              "        \n",
              "    \n",
              "            var tile_layer_7d1115db87b3917d2299b35be8e2cb60 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/d3a4c11c68bba9946d4ed3b8e6a16fa8-da73a270c1da51b362ad521dc4a54091/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_e6b6e244eac68c2abfcda706ac50be90);\n",
              "        \n",
              "    \n",
              "            var layer_control_f9667e04dd17393058c056b95f9c8eab = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_6ec574f59d2a07f0e6698c674f839ddf,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;median composite&quot; : tile_layer_7d1115db87b3917d2299b35be8e2cb60,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_f9667e04dd17393058c056b95f9c8eab.base_layers,\n",
              "                layer_control_f9667e04dd17393058c056b95f9c8eab.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_e6b6e244eac68c2abfcda706ac50be90);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Cloud masking function.\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  return image.updateMask(mask).select(BANDS).divide(10000)\n",
        "\n",
        "# The image input data is a 2018 cloud-masked median composite.\n",
        "image = L8SR.filterDate('2018-01-01', '2018-12-31').map(maskL8sr).median()\n",
        "\n",
        "# Using folium to visualize the imagery.\n",
        "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "map = folium.Map(location=[9.714855444616322, 76.32380968048625])\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:6\n",
        "Sample the regions and split it into testing and training batches."
      ],
      "metadata": {
        "id": "V7leoPtAvwKo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxj7RwamkPKN",
        "outputId": "16745cdd-f0a6-4669-e0a3-970d9ee1b7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'training': {'geometry': None,\n",
            "              'id': '000066e7d9bc84b3f95d_0',\n",
            "              'properties': {'B2': 0.049150001257658005,\n",
            "                             'B3': 0.06965000182390213,\n",
            "                             'B4': 0.08974999934434891,\n",
            "                             'B5': 0.1729000061750412,\n",
            "                             'B6': 0.2125999927520752,\n",
            "                             'B7': 0.15150000154972076,\n",
            "                             'landcover': 1,\n",
            "                             'random': 0.5484198857675888},\n",
            "              'type': 'Feature'}}\n",
            "{'testing': {'geometry': None,\n",
            "             'id': '00009f65e3c9ae02b84e_0',\n",
            "             'properties': {'B2': 0.05220000073313713,\n",
            "                            'B3': 0.062049999833106995,\n",
            "                            'B4': 0.03660000115633011,\n",
            "                            'B5': 0.01140000019222498,\n",
            "                            'B6': 0.006800000090152025,\n",
            "                            'B7': 0.005249999929219484,\n",
            "                            'landcover': 2,\n",
            "                            'random': 0.8210157114829347},\n",
            "             'type': 'Feature'}}\n"
          ]
        }
      ],
      "source": [
        "# Sample the image at the points and add a random column.\n",
        "sample = image.sampleRegions(\n",
        "  collection=LABEL_DATA, properties=[LABEL], scale=30).randomColumn()\n",
        "\n",
        "# Partition the sample approximately 70-30.\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "testing = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Print the first couple points to verify.\n",
        "pprint({'training': training.first().getInfo()})\n",
        "pprint({'testing': testing.first().getInfo()})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the existance of the output bucket.\n",
        "print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + OUTPUT_BUCKET)\n",
        "    else 'Can not find output Cloud Storage bucket.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkpS4vgN2LQw",
        "outputId": "cc4a73e9-eb37-4ea2-e975-04b11a3800a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Cloud Storage bucket.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:7\n",
        "Creating the training and testing task and export it to cloud storage."
      ],
      "metadata": {
        "id": "RytMY1GkxKZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tasks.\n",
        "training_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=training,\n",
        "  description='Training Export',\n",
        "  fileNamePrefix=TRAIN_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=testing,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=TEST_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)"
      ],
      "metadata": {
        "id": "Ri3MN1J2ut6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8W53EyysajF"
      },
      "outputs": [],
      "source": [
        "# Start the tasks.\n",
        "training_task.start()\n",
        "testing_task.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all tasks.\n",
        "pprint(ee.batch.Task.list())\n"
      ],
      "metadata": {
        "id": "YP7dRV1t2VZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4de6540-ae0c-4643-f643-ba1b5beaaefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Task 6JXILDICWEPVXDCOYSNPTTIG EXPORT_FEATURES: Testing Export (READY)>,\n",
            " <Task RQALUQND3TA7FSJCVO3USUMY EXPORT_FEATURES: Training Export (READY)>,\n",
            " <Task R3MQFWQSCIFOWK7PFHRB5V3X EXPORT_IMAGE: Image Export (FAILED)>,\n",
            " <Task 6ODV7YFZFA7RBIT4E6HJUJ2Q EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task O65CGNYRYNUZIWCWGNU37MLJ EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 5RLDGMAGFB5TN3IELTLJT4RK INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task ZR2X6J5QLX3HF4UVNEI22P54 INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task TJBCMZ4M2JTJPITDYNZTY75Y EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
            " <Task 4D3C4Z5RDG5EZQMXII3MTQQN EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task RGWIGAO2OEZRLV4MCQEHJ2ZX EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task OK5GMIJ6ULXWVM4AM6A2VQGT INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task 76RK3V4V35IDZ2SR2IDWPWYS EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
            " <Task IX6EDGJNNKPUWFRX244B5BGM EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task KHVOBTFAOCNAQPCXAO77QPTU EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task A3DXEZ4LGKNUIUNG5QUOZIE7 EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task 6SKQCYG263A5CXV5SE6NNLZ4 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 34SYTGYMFCUW3DDIHGQBLQWJ EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task VOJXG7COPC4RTXM45CQVH4MB EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task FY2773HOD3O2SGNVXBI236XS EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task 3KCJ4UZUEBRLC2EXRT4JYJF2 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 4DNYCIK7G7Y2TXR4PD7ILVOK EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task DFTELZKZS2MRQPYPTQSH5Y2J EXPORT_FEATURES: Training Export (COMPLETED)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYewzhjZkaya",
        "outputId": "1cdd1bc4-6ad5-4c49-e99c-2de66d754152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No training file found.\n",
            "No testing file found.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you can see the output bucket.  You must have write access.\n",
        "print('Found training file.' if tf.io.gfile.exists(TRAIN_FILE_PATH)\n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.io.gfile.exists(TEST_FILE_PATH)\n",
        "    else 'No testing file found.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:8\n",
        "Export these images to the cloud storage, on which prediction will be carried out.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4X9AGd6cxe3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaJ9UTEp-kc"
      },
      "outputs": [],
      "source": [
        "# Specify patch and file dimensions.\n",
        "image_export_options = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'maxFileSize': 104857600,\n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Setup the task.\n",
        "image_task = ee.batch.Export.image.toCloudStorage(\n",
        "  image=image,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=IMAGE_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  scale=30,\n",
        "  fileFormat='TFRecord',\n",
        "  region=EXPORT_REGION.toGeoJSON()['coordinates'],#Any cordinates from geojson can be inserted here as roi\n",
        "  formatOptions=image_export_options,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxElFrelkdF0"
      },
      "outputs": [],
      "source": [
        "image_task.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD7cKA1akfN5",
        "outputId": "3dd648e9-c54a-4566-aef0-4f8113301dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Task RZH7BYBAP6GB7EQRLYOT4X2I EXPORT_IMAGE: Image Export (READY)>,\n",
            " <Task 6JXILDICWEPVXDCOYSNPTTIG EXPORT_FEATURES: Testing Export (READY)>,\n",
            " <Task RQALUQND3TA7FSJCVO3USUMY EXPORT_FEATURES: Training Export (READY)>,\n",
            " <Task R3MQFWQSCIFOWK7PFHRB5V3X EXPORT_IMAGE: Image Export (FAILED)>,\n",
            " <Task 6ODV7YFZFA7RBIT4E6HJUJ2Q EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task O65CGNYRYNUZIWCWGNU37MLJ EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 5RLDGMAGFB5TN3IELTLJT4RK INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task ZR2X6J5QLX3HF4UVNEI22P54 INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task TJBCMZ4M2JTJPITDYNZTY75Y EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
            " <Task 4D3C4Z5RDG5EZQMXII3MTQQN EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task RGWIGAO2OEZRLV4MCQEHJ2ZX EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task OK5GMIJ6ULXWVM4AM6A2VQGT INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
            " <Task 76RK3V4V35IDZ2SR2IDWPWYS EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
            " <Task IX6EDGJNNKPUWFRX244B5BGM EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task KHVOBTFAOCNAQPCXAO77QPTU EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task A3DXEZ4LGKNUIUNG5QUOZIE7 EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task 6SKQCYG263A5CXV5SE6NNLZ4 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 34SYTGYMFCUW3DDIHGQBLQWJ EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task VOJXG7COPC4RTXM45CQVH4MB EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task FY2773HOD3O2SGNVXBI236XS EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task 3KCJ4UZUEBRLC2EXRT4JYJF2 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
            " <Task 4DNYCIK7G7Y2TXR4PD7ILVOK EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
            " <Task DFTELZKZS2MRQPYPTQSH5Y2J EXPORT_FEATURES: Training Export (COMPLETED)>]\n"
          ]
        }
      ],
      "source": [
        "pprint(ee.batch.Task.list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiMl4e_dkhbH",
        "outputId": "43709c4b-944e-42e2-e75a-429bb1caf9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Polling for task (id: RZH7BYBAP6GB7EQRLYOT4X2I).\n",
            "Done with image export.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "while image_task.active():\n",
        "  print('Polling for task (id: {}).'.format(image_task.id))\n",
        "  time.sleep(30)\n",
        "print('Done with image export.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:9\n",
        "Make the training data into TFR format for reading.\n"
      ],
      "metadata": {
        "id": "b1jShd2o4t5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IIYVJ4puekU",
        "outputId": "b3e80f95-f1e4-4d6a-f842-e63e373812b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'\\nw\\n\\x0e\\n\\x02B2\\x12\\x08\\x12\\x06\\n\\x04\\x83QI=\\n\\x0e\\n\\x02B3\\x12\\x08\\x12\\x06\\n\\x04\\xa9\\xa4\\x8e=\\n\\x0e\\n\\x02B4\\x12\\x08\\x12\\x06\\n\\x04\\xd9\\xce\\xb7=\\n\\x0e\\n\\x02B5\\x12\\x08\\x12\\x06\\n\\x04\\xb3\\x0c1>\\n\\x0e\\n\\x02B6\\x12\\x08\\x12\\x06\\n\\x04\\xd0\\xb3Y>\\n\\x0e\\n\\x02B7\\x12\\x08\\x12\\x06\\n\\x04\\xd1\"\\x1b>\\n\\x15\\n\\tlandcover\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
        "# Print the first record to check.\n",
        "print(iter(train_dataset).next())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baqz6dHKkobN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e49ebd-bce8-4783-874f-2a1eedfb1653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B2': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B3': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B4': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B5': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B6': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'B7': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'landcover': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
          ]
        }
      ],
      "source": [
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
        "\n",
        "pprint(features_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:10\n",
        "Now we need to make a parsing function for the data in the TFRecord files. The data comes in flattened 2D arrays per record and we want to use the first part of the array for input to the model and the last element of the array as the class label. The parsing function reads data from a serialized Example proto into a dictionary in which the keys are the feature names and the values are the tensors storing the value of the features for that example."
      ],
      "metadata": {
        "id": "rqqe2-G55M61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joJ8iW0PkqfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90129945-0b49-4cf8-9282-e86065a9c16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'B2': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04915], dtype=float32)>,\n",
            "  'B3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06965], dtype=float32)>,\n",
            "  'B4': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.08975], dtype=float32)>,\n",
            "  'B5': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.1729], dtype=float32)>,\n",
            "  'B6': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.2126], dtype=float32)>,\n",
            "  'B7': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.1515], dtype=float32)>},\n",
            " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "pprint(iter(parsed_dataset).next())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:11\n",
        "Another thing we might want to do as part of the input process is to create new features, for example NDVI, a vegetation index computed from reflectance in two spectral bands B5 and B4.This is the helper functions for that."
      ],
      "metadata": {
        "id": "cZm0c6qq5gf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQb2hvC2lEJ0"
      },
      "outputs": [],
      "source": [
        "def normalized_difference(a, b):\n",
        "  \"\"\"Compute normalized difference of two inputs.\n",
        "\n",
        "  Compute (a - b) / (a + b).  If the denomenator is zero, add a small delta.\n",
        "\n",
        "  Args:\n",
        "    a: an input tensor with shape=[1]\n",
        "    b: an input tensor with shape=[1]\n",
        "\n",
        "  Returns:\n",
        "    The normalized difference as a tensor.\n",
        "  \"\"\"\n",
        "  nd = (a - b) / (a + b)\n",
        "  nd_inf = (a - b) / (a + b + 0.000001)\n",
        "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)\n",
        "\n",
        "def add_NDVI(features, label):\n",
        "  \"\"\"Add NDVI to the dataset.\n",
        "  Args:\n",
        "    features: a dictionary of input tensors keyed by feature name.\n",
        "    label: the target label\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the input dictionary with an NDVI tensor added and the label.\n",
        "  \"\"\"\n",
        "  features['NDVI'] = normalized_difference(features['B5'], features['B4'])\n",
        "  return features, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:12\n",
        "Building the model using keras and fit it with training data."
      ],
      "metadata": {
        "id": "iJWDZFty5phK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhsQd6QBp_oR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f4d2c8-26c3-45bc-8f1a-094dc4189757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 1s 13ms/step - loss: 1.0401 - accuracy: 0.6286\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0107 - accuracy: 0.8571\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9654 - accuracy: 0.9143\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9441 - accuracy: 0.9143\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9088 - accuracy: 0.9714\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8724 - accuracy: 0.9429\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8293 - accuracy: 0.9429\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.8068 - accuracy: 0.9429\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7705 - accuracy: 0.9571\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.9429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34b697ddb0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Add NDVI.\n",
        "input_dataset = parsed_dataset.map(add_NDVI)\n",
        "\n",
        "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
        "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
        "# the label needs to be turned into a one-hot vector.\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.transpose(list(inputs.values())),\n",
        "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
        "\n",
        "# Map the to_tuple function, shuffle and batch.\n",
        "input_dataset = input_dataset.map(to_tuple).batch(8)\n",
        "\n",
        "# Define the layers in the model.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model with the specified loss function.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(x=input_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:13\n",
        "Evaluate the model"
      ],
      "metadata": {
        "id": "bwWOtae796UA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3PQqJB9qDTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb88e33f-bc28-447e-c285-1741fc22f785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7772 - accuracy: 0.8214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.777238667011261, 0.8214285969734192]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "test_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(add_NDVI)\n",
        "    .map(to_tuple)\n",
        "    .batch(1))\n",
        "\n",
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X1RRQayqGLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5150129e-7cd7-4111-9715-7d6d0ea515a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gs://environment_project/Image_pixel_demo_00000.tfrecord.gz',\n",
            " 'gs://environment_project/Image_pixel_demo_00001.tfrecord.gz']\n",
            "gs://environment_project/Image_pixel_demo_mixer.json\n"
          ]
        }
      ],
      "source": [
        "# Get a list of all the files in the output bucket.\n",
        "files_list = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n",
        "# Get only the files generated by the image export.\n",
        "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "image_files_list = []\n",
        "json_file = None\n",
        "for f in exported_files_list:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    image_files_list.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    json_file = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "image_files_list.sort()\n",
        "\n",
        "pprint(image_files_list)\n",
        "print(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mIkPzYlqKLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f311bb97-d8b8-4e78-e35e-bfa96c6e279a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'patchDimensions': [256, 256],\n",
            " 'patchesPerRow': 13,\n",
            " 'projection': {'affine': {'doubleMatrix': [0.00026949458523585647,\n",
            "                                            0.0,\n",
            "                                            -122.70007617412975,\n",
            "                                            0.0,\n",
            "                                            -0.00026949458523585647,\n",
            "                                            38.00089247493765]},\n",
            "                'crs': 'EPSG:4326'},\n",
            " 'totalPatches': 130}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the contents of the mixer file to a JSON object.\n",
        "json_text = !gsutil cat {json_file}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(json_text.nlstr)\n",
        "pprint(mixer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vurN9TDrqNxt"
      },
      "outputs": [],
      "source": [
        "# Get relevant info from the JSON mixer file.\n",
        "patch_width = mixer['patchDimensions'][0]\n",
        "patch_height = mixer['patchDimensions'][1]\n",
        "patches = mixer['totalPatches']\n",
        "patch_dimensions_flat = [patch_width * patch_height, 1]\n",
        "\n",
        "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
        "image_columns = [\n",
        "  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32)\n",
        "    for k in BANDS\n",
        "]\n",
        "\n",
        "# Parsing dictionary.\n",
        "image_features_dict = dict(zip(BANDS, image_columns))\n",
        "\n",
        "# Note that you can make one dataset from many files by specifying a list.\n",
        "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
        "\n",
        "# Parsing function.\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, image_features_dict)\n",
        "\n",
        "# Parse the data into tensors, one long tensor per patch.\n",
        "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
        "\n",
        "# Break our long tensors into many little ones.\n",
        "image_dataset = image_dataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "\n",
        "# Add additional features (NDVI).\n",
        "image_dataset = image_dataset.map(\n",
        "  # Add NDVI to a feature that doesn't have a label.\n",
        "  lambda features: add_NDVI(features, None)[0]\n",
        ")\n",
        "\n",
        "# Turn the dictionary in each record into a tuple without a label.\n",
        "image_dataset = image_dataset.map(\n",
        "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
        ")\n",
        "\n",
        "# Turn each patch into a batch.\n",
        "image_dataset = image_dataset.batch(patch_width * patch_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:14\n",
        "Do the prediction and write to cloud in TFRecord format."
      ],
      "metadata": {
        "id": "LJQuGFub_qRc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU7kqCjaqQ8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326852f2-b8b0-4602-bbbc-692d07661fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130/130 [==============================] - 512s 4s/step\n",
            "[[0.24734567 0.6163701  0.13628428]]\n"
          ]
        }
      ],
      "source": [
        "# Run prediction in batches, with as many steps as there are patches.\n",
        "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
        "\n",
        "# Note that the predictions come as a numpy array.  Check the first one.\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Writing to file ' + OUTPUT_IMAGE_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9VEQqlXtxNs",
        "outputId": "6b522157-9760-45d8-d3e1-184af263a3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing to file gs://environment_project/Classified_pixel_demo.TFRecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krjHmN41qTto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2724fa10-cc16-4de3-8138-50a8d01203f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with patch 1 of 130...\n",
            "Done with patch 2 of 130...\n",
            "Done with patch 3 of 130...\n",
            "Done with patch 4 of 130...\n",
            "Done with patch 5 of 130...\n",
            "Done with patch 6 of 130...\n",
            "Done with patch 7 of 130...\n",
            "Done with patch 8 of 130...\n",
            "Done with patch 9 of 130...\n",
            "Done with patch 10 of 130...\n",
            "Done with patch 11 of 130...\n",
            "Done with patch 12 of 130...\n",
            "Done with patch 13 of 130...\n",
            "Done with patch 14 of 130...\n",
            "Done with patch 15 of 130...\n",
            "Done with patch 16 of 130...\n",
            "Done with patch 17 of 130...\n",
            "Done with patch 18 of 130...\n",
            "Done with patch 19 of 130...\n",
            "Done with patch 20 of 130...\n",
            "Done with patch 21 of 130...\n",
            "Done with patch 22 of 130...\n",
            "Done with patch 23 of 130...\n",
            "Done with patch 24 of 130...\n",
            "Done with patch 25 of 130...\n",
            "Done with patch 26 of 130...\n",
            "Done with patch 27 of 130...\n",
            "Done with patch 28 of 130...\n",
            "Done with patch 29 of 130...\n",
            "Done with patch 30 of 130...\n",
            "Done with patch 31 of 130...\n",
            "Done with patch 32 of 130...\n",
            "Done with patch 33 of 130...\n",
            "Done with patch 34 of 130...\n",
            "Done with patch 35 of 130...\n",
            "Done with patch 36 of 130...\n",
            "Done with patch 37 of 130...\n",
            "Done with patch 38 of 130...\n",
            "Done with patch 39 of 130...\n",
            "Done with patch 40 of 130...\n",
            "Done with patch 41 of 130...\n",
            "Done with patch 42 of 130...\n",
            "Done with patch 43 of 130...\n",
            "Done with patch 44 of 130...\n",
            "Done with patch 45 of 130...\n",
            "Done with patch 46 of 130...\n",
            "Done with patch 47 of 130...\n",
            "Done with patch 48 of 130...\n",
            "Done with patch 49 of 130...\n",
            "Done with patch 50 of 130...\n",
            "Done with patch 51 of 130...\n",
            "Done with patch 52 of 130...\n",
            "Done with patch 53 of 130...\n",
            "Done with patch 54 of 130...\n",
            "Done with patch 55 of 130...\n",
            "Done with patch 56 of 130...\n",
            "Done with patch 57 of 130...\n",
            "Done with patch 58 of 130...\n",
            "Done with patch 59 of 130...\n",
            "Done with patch 60 of 130...\n",
            "Done with patch 61 of 130...\n",
            "Done with patch 62 of 130...\n",
            "Done with patch 63 of 130...\n",
            "Done with patch 64 of 130...\n",
            "Done with patch 65 of 130...\n",
            "Done with patch 66 of 130...\n",
            "Done with patch 67 of 130...\n",
            "Done with patch 68 of 130...\n",
            "Done with patch 69 of 130...\n",
            "Done with patch 70 of 130...\n",
            "Done with patch 71 of 130...\n",
            "Done with patch 72 of 130...\n",
            "Done with patch 73 of 130...\n",
            "Done with patch 74 of 130...\n",
            "Done with patch 75 of 130...\n",
            "Done with patch 76 of 130...\n",
            "Done with patch 77 of 130...\n",
            "Done with patch 78 of 130...\n",
            "Done with patch 79 of 130...\n",
            "Done with patch 80 of 130...\n",
            "Done with patch 81 of 130...\n",
            "Done with patch 82 of 130...\n",
            "Done with patch 83 of 130...\n",
            "Done with patch 84 of 130...\n",
            "Done with patch 85 of 130...\n",
            "Done with patch 86 of 130...\n",
            "Done with patch 87 of 130...\n",
            "Done with patch 88 of 130...\n",
            "Done with patch 89 of 130...\n",
            "Done with patch 90 of 130...\n",
            "Done with patch 91 of 130...\n",
            "Done with patch 92 of 130...\n",
            "Done with patch 93 of 130...\n",
            "Done with patch 94 of 130...\n",
            "Done with patch 95 of 130...\n",
            "Done with patch 96 of 130...\n",
            "Done with patch 97 of 130...\n",
            "Done with patch 98 of 130...\n",
            "Done with patch 99 of 130...\n",
            "Done with patch 100 of 130...\n",
            "Done with patch 101 of 130...\n",
            "Done with patch 102 of 130...\n",
            "Done with patch 103 of 130...\n",
            "Done with patch 104 of 130...\n",
            "Done with patch 105 of 130...\n",
            "Done with patch 106 of 130...\n",
            "Done with patch 107 of 130...\n",
            "Done with patch 108 of 130...\n",
            "Done with patch 109 of 130...\n",
            "Done with patch 110 of 130...\n",
            "Done with patch 111 of 130...\n",
            "Done with patch 112 of 130...\n",
            "Done with patch 113 of 130...\n",
            "Done with patch 114 of 130...\n",
            "Done with patch 115 of 130...\n",
            "Done with patch 116 of 130...\n",
            "Done with patch 117 of 130...\n",
            "Done with patch 118 of 130...\n",
            "Done with patch 119 of 130...\n",
            "Done with patch 120 of 130...\n",
            "Done with patch 121 of 130...\n",
            "Done with patch 122 of 130...\n",
            "Done with patch 123 of 130...\n",
            "Done with patch 124 of 130...\n",
            "Done with patch 125 of 130...\n",
            "Done with patch 126 of 130...\n",
            "Done with patch 127 of 130...\n",
            "Done with patch 128 of 130...\n",
            "Done with patch 129 of 130...\n",
            "Done with patch 130 of 130...\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the writer.\n",
        "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
        "\n",
        "# Every patch-worth of predictions we'll dump an example into the output file with a single feature that holds our predictions. Since our predictions\n",
        "# are already in the order of the exported data, the patches we create here will also be in the right order.\n",
        "\n",
        "patch = [[], [], [], []]\n",
        "cur_patch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  # Once we've seen a patches-worth of class_ids...\n",
        "  if (len(patch[0]) == patch_width * patch_height):\n",
        "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[0])),\n",
        "          'bareProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'vegProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'waterProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example to the file and clear our patch array so it's ready for\n",
        "    # another batch of   class ids\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], []]\n",
        "    cur_patch += 1\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URwDqzq6q9DS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486d4e3f-971d-449f-e96d-d863268ac3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 136331260  2023-05-24T13:17:36Z  gs://environment_project/Classified_pixel_demo.TFRecord\n",
            "TOTAL: 1 objects, 136331260 bytes (130.02 MiB)\n"
          ]
        }
      ],
      "source": [
        "!gsutil ls -l {OUTPUT_IMAGE_FILE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5to9W22XrAJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519dd9e4-289c-4a17-8f46-8d935f1ec7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading to projects/ee-ssasikumar/assets/Classified_pixel_demo\n"
          ]
        }
      ],
      "source": [
        "print('Uploading to ' + OUTPUT_ASSET_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:15\n",
        "Uplload the predicted tiles to earth engine assets and ovelay on the map for visualization."
      ],
      "metadata": {
        "id": "4_h_oA_q_0B_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ80hglUrJhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12d432d-e997-47d6-8591-12ca95ec3566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started upload task with ID: UT5AVQK3EUOWV47KS5PNRK3U\n"
          ]
        }
      ],
      "source": [
        "# Start the upload.\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jErGsQEXrNHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ecaaf7-6e6d-4d1b-cb07-6fe65047bae9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Task J6RZEJ7XPP3GZCGCVVMIS4K4 INGEST_IMAGE: Ingest image: \"projects/ee-ssasikumar/assets/Classified_pixel_demo\" (READY)>,\n",
              " <Task 56SMSYDH7NUMQIUOJRM5FXFZ INGEST_IMAGE: Ingest image: \"projects/ee-ssasikumar/assets/Image_pixel_demo_mixer\" (RUNNING)>,\n",
              " <Task I6KQEJEWDJTHPIDXSD6TBK5E INGEST_IMAGE: Ingest image: \"projects/ee-ssasikumar/assets/Image_pixel_demo_mixer\" (RUNNING)>,\n",
              " <Task WLXZULEG2IJPOERRM464C3TV INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task RZH7BYBAP6GB7EQRLYOT4X2I EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task 6JXILDICWEPVXDCOYSNPTTIG EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task RQALUQND3TA7FSJCVO3USUMY EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task R3MQFWQSCIFOWK7PFHRB5V3X EXPORT_IMAGE: Image Export (FAILED)>,\n",
              " <Task 6ODV7YFZFA7RBIT4E6HJUJ2Q EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task O65CGNYRYNUZIWCWGNU37MLJ EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task 5RLDGMAGFB5TN3IELTLJT4RK INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task ZR2X6J5QLX3HF4UVNEI22P54 INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task TJBCMZ4M2JTJPITDYNZTY75Y EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task 4D3C4Z5RDG5EZQMXII3MTQQN EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task RGWIGAO2OEZRLV4MCQEHJ2ZX EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task OK5GMIJ6ULXWVM4AM6A2VQGT INGEST_IMAGE: Ingest image: \"projects/earthengine-legacy/assets/users/ee-ssasikumar/Classified_pixel_demo\" (FAILED)>,\n",
              " <Task 76RK3V4V35IDZ2SR2IDWPWYS EXPORT_IMAGE: Image Export (COMPLETED)>,\n",
              " <Task IX6EDGJNNKPUWFRX244B5BGM EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task KHVOBTFAOCNAQPCXAO77QPTU EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task A3DXEZ4LGKNUIUNG5QUOZIE7 EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task 6SKQCYG263A5CXV5SE6NNLZ4 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task 34SYTGYMFCUW3DDIHGQBLQWJ EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task VOJXG7COPC4RTXM45CQVH4MB EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task FY2773HOD3O2SGNVXBI236XS EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task 3KCJ4UZUEBRLC2EXRT4JYJF2 EXPORT_FEATURES: Training Export (COMPLETED)>,\n",
              " <Task 4DNYCIK7G7Y2TXR4PD7ILVOK EXPORT_FEATURES: Testing Export (COMPLETED)>,\n",
              " <Task DFTELZKZS2MRQPYPTQSH5Y2J EXPORT_FEATURES: Training Export (COMPLETED)>]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "ee.batch.Task.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q756db4ZrQfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "97deaa2b-c676-4faa-9c7a-4fc01413e874"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7f1a7b58b4c0>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_ae30a5b749953d9b354f2ceff2b80cb0 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_ae30a5b749953d9b354f2ceff2b80cb0&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_ae30a5b749953d9b354f2ceff2b80cb0 = L.map(\n",
              "                &quot;map_ae30a5b749953d9b354f2ceff2b80cb0&quot;,\n",
              "                {\n",
              "                    center: [38.0, -122.5],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_e10de0a3af108be6614a021be892c1f2 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_ae30a5b749953d9b354f2ceff2b80cb0);\n",
              "        \n",
              "    \n",
              "            var tile_layer_05a71fb459203d33243492d934b26121 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/6a1e9ae64dd721e67065d5dc5c34f3e9-a0d342aed6d177aa474abcf75ed72ca7/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_ae30a5b749953d9b354f2ceff2b80cb0);\n",
              "        \n",
              "    \n",
              "            var tile_layer_34c8cd518ed600271fadfb9395eb0bf3 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/e4781b19abd088919cd62d5d893cb59f-85f8800b7a7f2a4a5762004c66f21175/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_ae30a5b749953d9b354f2ceff2b80cb0);\n",
              "        \n",
              "    \n",
              "            var layer_control_74818a8cbc6b4fd2b8ea7d052be07502 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_e10de0a3af108be6614a021be892c1f2,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;prediction&quot; : tile_layer_05a71fb459203d33243492d934b26121,\n",
              "                    &quot;probability&quot; : tile_layer_34c8cd518ed600271fadfb9395eb0bf3,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_74818a8cbc6b4fd2b8ea7d052be07502.base_layers,\n",
              "                layer_control_74818a8cbc6b4fd2b8ea7d052be07502.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_ae30a5b749953d9b354f2ceff2b80cb0);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "predictions_image = ee.Image(OUTPUT_ASSET_ID)\n",
        "\n",
        "prediction_vis = {\n",
        "  'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 2,\n",
        "  'palette': ['red', 'green', 'blue']\n",
        "}\n",
        "probability_vis = {'bands': ['bareProb', 'vegProb', 'waterProb'], 'max': 0.5}\n",
        "\n",
        "prediction_map_id = predictions_image.getMapId(prediction_vis)\n",
        "probability_map_id = predictions_image.getMapId(probability_vis)\n",
        "\n",
        "map = folium.Map(location=[38., -122.5])\n",
        "folium.TileLayer(\n",
        "  tiles=prediction_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probability_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64lgVojWpZ2H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}